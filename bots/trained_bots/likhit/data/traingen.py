"""
This script splits the episode data generated by episodegen.py into
train, test, and validation shelves. Each shelve contains an entry
for each of the steps in each episode.
"""
import argparse
import glob
import os
import pickle
import random
import shelve
from torch.utils.data import Dataset

class ShelveManager(object):
    """
    Manages the train, test, and validation shelves. Also
    responsible for splitting the data into these shelves.

    Args:
        shelve_dir (str): Path to the directory in which the
            shelves will be created.
        train (float): The proportion of steps that should go
            into the train dataset.
        test (float): The proportion of steps that should go into
            the test dataset.

    The validation dataset propertion is 1 - (train + test).
    """
    _LAST_INDEX_KEY = 'last_ind'

    def __init__(self, shelve_dir, train, test):
        self.shelve_dir = shelve_dir
        self._train = train
        self._test  = self._train + test
        self._val   = 1
        self._rand = random.Random()
        self._open()

    def _open(self):
        """
        Opens the shelves.
        """
        self._train_db = shelve.open(os.path.join(self.shelve_dir, 'train'))
        self._test_db  = shelve.open(os.path.join(self.shelve_dir, 'test'))
        self._val_db   = shelve.open(os.path.join(self.shelve_dir, 'val'))

        self._last_train_index = self._train_db.get(ShelveManager._LAST_INDEX_KEY, 0)
        self._last_test_index = self._test_db.get(ShelveManager._LAST_INDEX_KEY, 0)
        self._last_val_index = self._val_db.get(ShelveManager._LAST_INDEX_KEY, 0)
        return self

    def add(self, step):
        """
        Adds a step instance into one of the datasets.
        """
        rand = self._rand.random()
        if 0 <= rand < self._train:
            self._train_db[str(self._last_train_index)] = step
            self._last_train_index += 1
        elif self._train <= rand < self._test:
            self._test_db[str(self._last_test_index)] = step
            self._last_test_index += 1
        elif self._test <= rand:
            self._val_db[str(self._last_val_index)] = step
            self._last_val_index += 1

    def close(self):
        """
        Close the shelves.
        """
        self._train_db[ShelveManager._LAST_INDEX_KEY] = self._last_train_index
        self._test_db[ShelveManager._LAST_INDEX_KEY] = self._last_test_index
        self._val_db[ShelveManager._LAST_INDEX_KEY] = self._last_val_index

        self._train_db.close()
        self._test_db.close()
        self._val_db.close()

        del self._last_train_index
        del self._last_test_index
        del self._last_val_index

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.close()


class ShelveDataset(Dataset):
    """
    Dataset which reads from a shelve where the keys are the index
    of an entry.

    Args:
        shelve_file (str): The file path containing the dataset shelve.
        transform (callable): Transforms to be applied to the data.
    """
    def __init__(self, shelve_file, transform=None):
        self.shelve_file = shelve_file
        self.transform = transform
        self._shelve = shelve.open(self.shelve_file, 'c')

    def __len__(self):
        return len(self._shelve) - 1

    def __getitem__(self, idx):
        item = self._shelve[str(idx)]
        if self.transform:
            item = self.transform(item)
        return item

    def close(self):
        self._shelve.close()

    def __enter__(self):
        self._shelve.__enter__()
        return self

    def __exit__(self, type, value, traceback):
        self.close()


def main(args):
    with ShelveManager(args.save_dir, args.train, args.test) as shelve_manager:
        for data_file in glob.glob(args.episode_data_glob):
            with open(data_file, 'rb') as file_handle:
                data = pickle.load(file_handle)
            players = data.result['playernames']
            for step in data.history:
                step.players = players
                shelve_manager.add(step)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Generate train, test and validation splits form episode data.')
    parser.add_argument('--episode_data_glob', help='Glob identifing all episode data files to use')
    parser.add_argument('--save_dir', help='Path to the directory in which the dataset shelves should be saved.')
    parser.add_argument('--train', type=float, help='Proportion of the data between [0, 1] that will go into the train split.')
    parser.add_argument('--test', type=float, help='Proportion of the data between [0, 1] that will go into the test split.')
    args = parser.parse_args()
    main(args)
