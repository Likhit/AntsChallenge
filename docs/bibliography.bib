@online{antschallenge,
    title={Ants Challenge},
    author={University of Waterloo and Google},
    url={http://ants.aichallenge.org/}
}

@online{winnerbot,
    title={Xanthis},
    author={Mathis Lichtenberger},
    url={https://web.archive.org/web/20120215072119/http://xathis.com/posts/ai-challenge-2011-ants.html}
}

@article{qlearning,
    author = {Watkins, Christopher},
    year = {1989},
    month = {01},
    pages = {},
    title = {Learning From Delayed Rewards}
}

@article{Sutton1988,
    author="Sutton, Richard S.",
    title="Learning to predict by the methods of temporal differences",
    journal="Machine Learning",
    year="1988",
    month="Aug",
    day="01",
    volume="3",
    number="1",
    pages="9--44",
    abstract="This article introduces a class of incremental learning procedures specialized for prediction-that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.",
    issn="1573-0565",
    doi="10.1007/BF00115009",
    url="https://doi.org/10.1007/BF00115009"
}

@article{DBLP:journals/corr/HasseltGS15,
    author={Hado van Hasselt and Arthur Guez and David Silver},
    title={Deep Reinforcement Learning with Double Q-learning},
    journal={CoRR},
    volume={abs/1509.06461},
    year={2015},
    url={http://arxiv.org/abs/1509.06461},
    archivePrefix={arXiv},
    eprint={1509.06461},
    timestamp={Mon, 13 Aug 2018 16:47:32 +0200},
    biburl={https://dblp.org/rec/bib/journals/corr/HasseltGS15},
    bibsource={dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MnihBMGLHSK16,
    author={Volodymyr Mnih and Adri{\`{a}} Puigdom{\`{e}}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
    title={Asynchronous Methods for Deep Reinforcement Learning},
    journal={CoRR},
    volume={abs/1602.01783},
    year={2016},
    url={http://arxiv.org/abs/1602.01783},
    archivePrefix={arXiv},
    eprint={1602.01783},
    timestamp={Mon, 13 Aug 2018 16:47:40 +0200},
    biburl={https://dblp.org/rec/bib/journals/corr/MnihBMGLHSK16},
    bibsource={dblp computer science bibliography, https://dblp.org}
}

@article{AlphaGo,
    author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
    title={Mastering the game of Go without human knowledge},
    journal={Nature},
    year={2017},
    month={Oct},
    day={18},
    publisher={Macmillan Publishers Limited, part of Springer Nature. All rights reserved. SN -},
    volume={550},
    pages={354 EP -},
    note={Article},
    url={https://doi.org/10.1038/nature24270}
}

@article{Mnih2015,
    author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    title={Human-level control through deep reinforcement learning},
    journal={Nature},
    year={2015},
    month={Feb},
    day={25},
    publisher={Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN -},
    volume={518},
    pages={529 EP -},
    url={https://doi.org/10.1038/nature14236}
}

@article{DBLP:journals/corr/TampuuMKKKAAV15,
    author={Ardi Tampuu and Tambet Matiisen and Dorian Kodelja and Ilya Kuzovkin and Kristjan Korjus and Juhan Aru and Jaan Aru and Raul Vicente},
    title={Multiagent Cooperation and Competition with Deep Reinforcement Learning},
    journal={CoRR},
    volume={abs/1511.08779},
    year={2015},
    url={http://arxiv.org/abs/1511.08779},
    archivePrefix={arXiv},
    eprint={1511.08779},
    timestamp={Mon, 13 Aug 2018 16:46:26 +0200},
    biburl={https://dblp.org/rec/bib/journals/corr/TampuuMKKKAAV15},
    bibsource={dblp computer science bibliography, https://dblp.org}
}
